{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XNLI_Fine-tuning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2s28zozugGTN"
      },
      "outputs": [],
      "source": [
        "## Mount Drive to colab.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval\n",
        "!pip install swish\n",
        "!pip install transformers==3.0.0\n",
        "!pip install tokenizers==0.10.0\n",
        "\n",
        "# Libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torchtext.legacy.data import Field, TabularDataset, BucketIterator, Iterator\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizer, BertForSequenceClassification,BertConfig\n",
        "from tokenizers import Tokenizer, BertWordPieceTokenizer \n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm, trange\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertConfig\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertForTokenClassification, AdamW\n",
        "from transformers.modeling_bert import load_tf_weights_in_bert\n",
        "import transformers\n",
        "import logging\n",
        "import argparse\n",
        "import glob\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import pdb\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from seqeval.metrics import precision_score, recall_score, f1_score , accuracy_score\n",
        "logger = logging.getLogger(__name__)\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from seqeval.metrics import f1_score, accuracy_score\n",
        "from seqeval.metrics import classification_report\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix as cnf_mtx\n",
        "import sklearn.metrics\n"
      ],
      "metadata": {
        "id": "Bf-Jxlrcgndz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT(nn.Module):\n",
        "\n",
        "    def __init__(self,model_type,model_ckpt,bert_config):\n",
        "        super(BERT, self).__init__()\n",
        "\n",
        "        # options_name = \"bert-base-uncased\"\n",
        "        if(model_type=='tensorflow'):\n",
        "          self.encoder=load_BFTC_from_TF_ckpt(bert_config, model_ckpt, BertForSequenceClassification)\n",
        "        elif(model_type=='pytorch'):\n",
        "          self.encoder = BertForSequenceClassification.from_pretrained(model_ckpt, config=bert_config)\n",
        "\n",
        "        # self.encoder = BertForSequenceClassification.from_pretrained(options_name)\n",
        "\n",
        "    def forward(self, text, label):\n",
        "        loss, text_fea = self.encoder(text, labels=label)[:2]\n",
        "\n",
        "        return loss, text_fea\n",
        "\n",
        "# Save and Load Functions\n",
        "\n",
        "def save_checkpoint(save_path, model, valid_loss):\n",
        "\n",
        "    if save_path == None:\n",
        "        return\n",
        "    \n",
        "    state_dict = {'model_state_dict': model.state_dict(),\n",
        "                  'valid_loss': valid_loss}\n",
        "    \n",
        "    torch.save(state_dict, save_path)\n",
        "    print(f'Model saved to ==> {save_path}')\n",
        "\n",
        "def load_checkpoint(load_path, model):\n",
        "    \n",
        "    if load_path==None:\n",
        "        return\n",
        "    \n",
        "    state_dict = torch.load(load_path, map_location=device)\n",
        "    print(f'Model loaded from <== {load_path}')\n",
        "    \n",
        "    model.load_state_dict(state_dict['model_state_dict'])\n",
        "    return state_dict['valid_loss']\n",
        "\n",
        "\n",
        "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
        "\n",
        "    if save_path == None:\n",
        "        return\n",
        "    \n",
        "    state_dict = {'train_loss_list': train_loss_list,\n",
        "                  'valid_loss_list': valid_loss_list,\n",
        "                  'global_steps_list': global_steps_list}\n",
        "    \n",
        "    torch.save(state_dict, save_path)\n",
        "    print(f'Model saved to ==> {save_path}')\n",
        "\n",
        "\n",
        "def load_metrics(load_path):\n",
        "\n",
        "    if load_path==None:\n",
        "        return\n",
        "    \n",
        "    state_dict = torch.load(load_path, map_location=device)\n",
        "    print(f'Model loaded from <== {load_path}')\n",
        "    \n",
        "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']\n",
        "def load_BFTC_from_TF_ckpt(bert_config, ckpt_path, model_class):\n",
        "    config=bert_config\n",
        "    model = transformers.BertForPreTraining(config)\n",
        "    load_tf_weights_in_bert(model,config, ckpt_path)\n",
        "    state_dict=model.state_dict()\n",
        "    # logging.info(json.dumps(config))\n",
        "    model = model_class(config)\n",
        "    # Load from a PyTorch state_dict\n",
        "    old_keys = []\n",
        "    new_keys = []\n",
        "    for key in state_dict.keys():\n",
        "        new_key = None\n",
        "        if 'gamma' in key:\n",
        "            new_key = key.replace('gamma', 'weight')\n",
        "        if 'beta' in key:\n",
        "            new_key = key.replace('beta', 'bias')\n",
        "        if new_key:\n",
        "            old_keys.append(key)\n",
        "            new_keys.append(new_key)\n",
        "    for old_key, new_key in zip(old_keys, new_keys):\n",
        "        state_dict[new_key] = state_dict.pop(old_key)\n",
        "\n",
        "    missing_keys = []\n",
        "    unexpected_keys = []\n",
        "    error_msgs = []\n",
        "    # copy state_dict so _load_from_state_dict can modify it\n",
        "    metadata = getattr(state_dict, '_metadata', None)\n",
        "    state_dict = state_dict.copy()\n",
        "    if metadata is not None:\n",
        "        state_dict._metadata = metadata\n",
        "\n",
        "    def load(module, prefix=''):\n",
        "        local_metadata = {} if metadata is None else metadata.get(prefix[:-1], {})\n",
        "        module._load_from_state_dict(\n",
        "            state_dict, prefix, local_metadata, True, missing_keys, unexpected_keys, error_msgs)\n",
        "        for name, child in module._modules.items():\n",
        "            if child is not None:\n",
        "                load(child, prefix + name + '.')\n",
        "    start_prefix = ''\n",
        "    if not hasattr(model, 'bert') and any(s.startswith('bert.') for s in state_dict.keys()):\n",
        "        start_prefix = 'bert.'\n",
        "    load(model, prefix=start_prefix)\n",
        "    if len(missing_keys) > 0:\n",
        "        logger.info(\"Weights of {} not initialized from pretrained model: {}\".format(\n",
        "            model.__class__.__name__, missing_keys))\n",
        "    if len(unexpected_keys) > 0:\n",
        "        logger.info(\"Weights from pretrained model not used in {}: {}\".format(\n",
        "            model.__class__.__name__, unexpected_keys))\n",
        "    if len(error_msgs) > 0:\n",
        "        raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n",
        "                           model.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "FjvqtO9mhEfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class dataset(object):\n",
        "  def __init__(self, path,lang,data_type,device,batch_size_taken,fields):\n",
        "      self.path=path\n",
        "      self.lang=lang\n",
        "\n",
        "      if(data_type=='train'):\n",
        "        self.tabular_data,_,_=TabularDataset.splits(path=path+\"/\", train=data_type+'-'+lang+'.tsv',validation='valid'+'-'+lang+'.tsv',test='test'+'-'+lang+'.tsv', format='TSV', fields=fields, skip_header=True)\n",
        "        self.iter=BucketIterator(self.tabular_data, batch_size=batch_size_taken, sort_key=lambda x: len(x.text), device=device, train=True, sort=False, sort_within_batch=False)\n",
        "      elif(data_type=='valid'):\n",
        "        # _,self.tabular_data,_=TabularDataset.splits(path=path+\"/\", validation=data_type+'-'+lang+'.tsv',train=data_type+'-'+lang+'.tsv',test=data_type+'-'+lang+'.tsv' format='TSV', fields=fields, skip_header=True)\n",
        "        self.tabular_data=TabularDataset(path=path+\"/\"+data_type+'-'+lang+'.tsv', format='TSV', fields=fields, skip_header=True)\n",
        "        self.iter=BucketIterator(self.tabular_data, batch_size=batch_size_taken, sort_key=lambda x: len(x.text), device=device, train=False, sort=False, sort_within_batch=False)\n",
        "      else:\n",
        "        # self.tabular_data=TabularDataset.splits(path=path+\"/\", test=data_type+'-'+lang+'.tsv', format='TSV', fields=fields, skip_header=True)\n",
        "        self.tabular_data=TabularDataset(path=path+\"/\"+data_type+'-'+lang+'.tsv', format='TSV', fields=fields, skip_header=True)\n",
        "        self.iter=Iterator(self.tabular_data, batch_size=batch_size_taken, device=device, train=False, shuffle=False, sort=False)\n",
        "\n",
        "  def get_iter_loader(self):\n",
        "  \t  return self.iter\n",
        "  def get_tabular_data(self):\n",
        "    return self.tabular_data\n",
        "\n",
        "def evaluate(model, test_loader,label_field,out_dir,test_lang,device,tokenizer):\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "    text_list=[]\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for (labels,  text), _ in test_loader:\n",
        "                # print(labels)\n",
        "                labels = labels.type(torch.LongTensor)           \n",
        "                labels = labels.to(device)\n",
        "                text = text.type(torch.LongTensor)  \n",
        "                text = text.to(device)\n",
        "                loss,output = model(text, labels)\n",
        "                y_pred.extend(torch.argmax(output, 1).tolist())\n",
        "                y_true.extend(labels.tolist())\n",
        "                # print(len(y_pred),len(y_true))\n",
        "                text_list.extend([[tokenizer.id_to_token(x) for x in t] for t in text.tolist()] )\n",
        "                # print(text.tolist())\n",
        "                # print([tokenizer.convert_ids_to_tokens(t,True) for t in text.tolist()])\n",
        "                # break\n",
        "\n",
        "                # text_list.extend([ ' '.join(tokenizer.convert_ids_to_tokens(t,True)) for t in text.tolist()])\t\n",
        "    # print('Classification Report:')\n",
        "    # print(y_true)\n",
        "    # print(y_pred)\n",
        "    # print(len(y_true),len(y_pred),len(text_list))\n",
        "\n",
        "\n",
        "    outfile=open(out_dir+'/'+'pred.csv','w')\n",
        "    outfile.write('True\\tPredicted\\tText\\n')\n",
        "    real_tags=list((label_field.vocab.stoi.keys()))\n",
        "    \n",
        "    for i in range(len(y_true)):\n",
        "    \t# outfile.write(str(y_true[i])+'\\t'+str(y_pred[i])+'\\t'+str(text_list[i]))\n",
        "    \toutfile.write(real_tags[y_true[i]]+'\\t'+real_tags[y_pred[i]]+'\\t'+str(text_list[i])+'\\n')\n",
        "    outfile.close()\n",
        "\n",
        "    # label_field.vocab.stoi.keys()\n",
        "    print(\"Evaluation on Language: \",test_lang)\n",
        "    print(\"Accuracy Score \",sklearn.metrics.accuracy_score(y_true,y_pred))\n",
        "    print(\"Micro F1\",sklearn.metrics.f1_score(y_true,y_pred,average='micro'))\n",
        "    print(\"Macro F1\",sklearn.metrics.f1_score(y_true,y_pred,average='macro'))\n",
        "    print(\"Classwise precision_recall_fscore_support:\\n\", sklearn.metrics.precision_recall_fscore_support(y_true,y_pred))\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(sklearn.metrics.confusion_matrix([real_tags[t] for t in y_true],[real_tags[t] for t in y_pred] ) )\n",
        "    outfile=open(out_dir+'/'+'report.txt','w')\n",
        "    print(real_tags)\n",
        "    outfile.write(\"Accuracy Score \"+str(sklearn.metrics.accuracy_score(y_true,y_pred)))\n",
        "    outfile.write(\"\\nMicro F1\"+str(sklearn.metrics.f1_score(y_true,y_pred,average='micro')))\n",
        "    outfile.write(\"\\nMacro F1\"+str(sklearn.metrics.f1_score(y_true,y_pred,average='macro')))\n",
        "    outfile.write(\"\\nClasswise precision_recall_fscore_support:\\n\")\n",
        "    outfile.write(str(sklearn.metrics.precision_recall_fscore_support(y_true,y_pred)[0])+'\\n')\n",
        "    outfile.write(str(sklearn.metrics.precision_recall_fscore_support(y_true,y_pred)[1])+'\\n')\n",
        "    outfile.write(str(sklearn.metrics.precision_recall_fscore_support(y_true,y_pred)[2])+'\\n')\n",
        "    outfile.write(str(sklearn.metrics.precision_recall_fscore_support(y_true,y_pred)[3])+'\\n')\n",
        "\n",
        "    outfile.write(\"\\nConfusion Matrix: \\n\"+str(sklearn.metrics.confusion_matrix([real_tags[t] for t in y_true],[real_tags[t] for t in y_pred] )))\n",
        "    outfile.close()\n",
        "  # Training Function\n",
        "\n",
        "def train(destination_folder,\n",
        "    \t\t  dataset_path,\n",
        "          bert_config_path,\n",
        "          model_type,\n",
        "          model_path,\n",
        "          do_lower_case,\n",
        "          train_lang,\n",
        "          test_langs_list,\n",
        "          num_epochs = 5,\n",
        "          eval_every_steps = -1,\n",
        "\t\t      MAX_SEQ_LEN = 128,\n",
        "          criterion = nn.CrossEntropyLoss(),\n",
        "          learning_rate=2e-5,\n",
        "          batch_size=32,\n",
        "          best_valid_loss = float(\"Inf\"),\n",
        "          vocab_file_path = \"\",\n",
        "          tokenizer_path = \"\"):\n",
        "\n",
        "\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    print(\"Device: \",device)    \n",
        "\n",
        "    if tokenizer_path:\n",
        "      tokenizer = Tokenizer.from_file(tokenizer_path)\n",
        "    else:\n",
        "      tokenizer = BertWordPieceTokenizer(vocab_file_path, lowercase=do_lower_case, strip_accents=False)\n",
        "\n",
        "   # Model parameter\n",
        "    PAD_INDEX = tokenizer.token_to_id(\"[PAD]\")\n",
        "    UNK_INDEX = tokenizer.token_to_id(\"[UNK]\")\n",
        "    CLS_INDEX = tokenizer.token_to_id(\"[CLS]\")\n",
        "    SEP_INDEX = tokenizer.token_to_id(\"[SEP]\")\n",
        "\n",
        "    def encode_tok(x):\n",
        "      ids = tokenizer.encode(x).ids\n",
        "      # print(\"ensure SEP\")\n",
        "      # print(ids.count(SEP_INDEX))\n",
        "      assert(SEP_INDEX in ids)\n",
        "      if ids[0] != CLS_INDEX: ids = [CLS_INDEX] + ids\n",
        "      if ids[-1] != SEP_INDEX: ids = ids + [SEP_INDEX]\n",
        "      return ids\n",
        "\n",
        "    # Fields\n",
        "    # label_field = Field(sequential=False,  batch_first=True, dtype=torch.float)\n",
        "    label_field = Field(sequential=False,  batch_first=True,unk_token=None)\n",
        "    text_field = Field(use_vocab=False, tokenize=encode_tok, lower=False, include_lengths=False, batch_first=True,\n",
        "                      fix_length=MAX_SEQ_LEN, pad_token=PAD_INDEX, unk_token=UNK_INDEX)\n",
        "    fields = [('label', label_field), ('text', text_field)]\n",
        "\n",
        "\n",
        "    train_data_obj=dataset(\tdataset_path+'/',train_lang,'train',device,batch_size,fields)\n",
        "    # train_lang_train,train_lang_valid,train_lang_test=TabularDataset.splits(path=dataset_path+\"/\", train='train'+'-'+train_lang+'.tsv',\n",
        "                                                                            # validation='valid'+'-'+train_lang+'.tsv',test='test'+'-'+train_lang+'.tsv', format='TSV', fields=fields, skip_header=True)\n",
        "    label_field.build_vocab(train_data_obj.get_tabular_data(),min_freq=1)\n",
        "    # label_field.build_vocab(train_lang_train,min_freq=1)\n",
        "    print(\"Tags: \",list((label_field.vocab.stoi.keys())))\n",
        "    print(\"Number of Tags:\",len(list((label_field.vocab.stoi.keys()))))\n",
        "\n",
        "    bert_config            = BertConfig.from_json_file(bert_config_path)\n",
        "    bert_config.num_labels=len(label_field.vocab.stoi.keys())\n",
        "    model = BERT(model_type,model_path,bert_config)\n",
        "    model.cuda()\n",
        "    print(\"Model successfully loaded from\",model_path)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    \n",
        " \n",
        "    valid_data_obj=dataset(dataset_path+'/',train_lang,'valid',device,batch_size,fields)\n",
        "\n",
        "    test_data_obj_list=[]\n",
        "\n",
        "    for test_lang in test_langs_list:\n",
        "    \ttest_data_obj_list.append(dataset(dataset_path+'/',test_lang,'test',device,batch_size,fields))\n",
        "\n",
        "\n",
        "    \n",
        "    # initialize running values    \n",
        "    running_loss = 0.0\n",
        "    valid_running_loss = 0.0\n",
        "    global_step = 0\n",
        "    train_loss_list = []\n",
        "    valid_loss_list = []\n",
        "    global_steps_list = []\n",
        "\n",
        "    # training loop\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loader=train_data_obj.get_iter_loader()\n",
        "        len_train_epoch=len(train_loader)\n",
        "        print(\"Epoch Num:\",epoch)\n",
        "        print(\"total steps in one epoch:\",len(train_loader))\n",
        "        train_step_count=0\n",
        "        for (labels, text), _ in train_loader:\n",
        "            labels = labels.type(torch.LongTensor)           \n",
        "            labels = labels.to(device)\n",
        "            text = text.type(torch.LongTensor)  \n",
        "            text = text.to(device)\n",
        "            # print(tokenizer.convert_ids_to_tokens(text,True))\n",
        "            # print(tokenizer.convert_ids_to_tokens(text[1],True))\n",
        "            # print([tokenizer.convert_ids_to_tokens(t,True) for t in text.tolist()])\n",
        "\n",
        "            output = model(text, labels)\n",
        "            loss, output = output\n",
        "            if(train_step_count%20==0):\n",
        "              print(train_step_count,str(loss.item()))\n",
        "              # print(output)\n",
        "              # print([tokenizer.convert_ids_to_tokens(t,True) for t in text.tolist()])\n",
        "            train_step_count+=1\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # update running values\n",
        "            running_loss += loss.item()\n",
        "            global_step += 1\n",
        "\n",
        "            # evaluation step\n",
        "            if (train_step_count==len_train_epoch) or (train_step_count==eval_every_steps):\n",
        "                model.eval()\n",
        "                with torch.no_grad():                    \n",
        "                  print(\"Evaluating on validation data\")\n",
        "                  \n",
        "                  valid_loader=valid_data_obj.get_iter_loader()\n",
        "                    # validation loop\n",
        "                  for (labels,  text), _ in valid_loader:\n",
        "                    labels = labels.type(torch.LongTensor)           \n",
        "                    labels = labels.to(device)\n",
        "                    text = text.type(torch.LongTensor)  \n",
        "                    text = text.to(device)\n",
        "                    output = model(text, labels)\n",
        "                    loss, _ = output\n",
        "                    \n",
        "                    valid_running_loss += loss.item()\n",
        "\n",
        "                # evaluation\n",
        "                average_train_loss = running_loss / eval_every_steps\n",
        "                average_valid_loss = valid_running_loss / len(valid_loader)\n",
        "                train_loss_list.append(average_train_loss)\n",
        "                valid_loss_list.append(average_valid_loss)\n",
        "                global_steps_list.append(global_step)\n",
        "\n",
        "                # resetting running values\n",
        "                running_loss = 0.0                \n",
        "                valid_running_loss = 0.0\n",
        "                model.train()\n",
        "\n",
        "                # print progress\n",
        "                print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
        "                      .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\n",
        "                              average_train_loss, average_valid_loss))\n",
        "                \n",
        "                # checkpoint\n",
        "                try:\n",
        "                  os.mkdir(destination_folder)\n",
        "                except:\n",
        "                  print('error while creating : ',destination_folder)\n",
        "                  temp=1\n",
        "                dir_name=destination_folder+'/text_classification/'\n",
        "                try:\n",
        "                  os.mkdir(dir_name)\n",
        "                except:\n",
        "                  print('error while creating : ',dir_name)\n",
        "                  temp=1\n",
        "\n",
        "                \n",
        "                if best_valid_loss > average_valid_loss:\n",
        "                    best_valid_loss = average_valid_loss\n",
        "                    save_checkpoint(destination_folder+'/text_classification/' + '/' + 'model.pt', model, best_valid_loss)\n",
        "                    save_metrics(destination_folder+'/text_classification/' + '/' + 'metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
        "                break\n",
        "\n",
        "        print(\"Evaluation on test data\")\n",
        "        for test_lang_obj in test_data_obj_list:\n",
        "\n",
        "\n",
        "          try:\n",
        "            os.mkdir(destination_folder)\n",
        "          except:\n",
        "            print('error while creating : ',destination_folder)\n",
        "            temp=1\n",
        "          dir_name=destination_folder+'/text_classification/'\n",
        "          try:\n",
        "            os.mkdir(dir_name)\n",
        "          except:\n",
        "            print('error while creating : ',dir_name)\n",
        "            temp=1\n",
        "          dir_name=dir_name+'/classification_reports/'\n",
        "          # dir_name='/content/drive/My Drive/btp/bert_increased_vocab/hindi_bert/hindi_and_panjabi_bert_train_on_hi-t13n-pa/'\n",
        "          try:\n",
        "            os.mkdir(dir_name)\n",
        "          except:\n",
        "            print('error while creating : ',dir_name)\n",
        "            temp=1\n",
        "          dir_name=dir_name+'epoch_num_'+str(epoch)+'/'\n",
        "          try:\n",
        "            os.mkdir(dir_name)\n",
        "          except:\n",
        "            print('error while creating : ',dir_name)\n",
        "            temp=1\n",
        "          dir_name=dir_name+test_lang_obj.lang+'/'\n",
        "          try:\n",
        "            os.mkdir(dir_name)\n",
        "          except:\n",
        "            print('error while creating : ',dir_name)\n",
        "            temp=1\n",
        "\n",
        "          evaluate(model,test_lang_obj.get_iter_loader(),label_field,dir_name,test_lang_obj.lang,device,tokenizer)        \n",
        "    \n",
        "    save_metrics(destination_folder + '/' + 'metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
        "    print('Finished Training!')\n"
      ],
      "metadata": {
        "id": "dUgwqPlwhGU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "do_lower_case=False ## Note. Keep it False if involving any Indian Language or Scirpt of Indian Origin\n",
        "MAX_SEQ_LEN = 128 ## Depends on the model architechture\n",
        "batch_size=32\n",
        "learning_rate=2e-5\n",
        "epochs=16 ## Number of Training Loops\n",
        "eval_every_steps=400 ## Number of Training Iteration in each Training Loop after which evaluation is done. \n",
        "                     ## Final model selection manually done based on Validation Loss on Train_Language.  \n",
        "\n",
        "bert_config_path=\"\" ## BERT Config path.              Sample : \"/content/drive/My Drive/btp/bert_increased_vocab/hindi_bert/bpe_hindi_marathi_config.json\"\n",
        "vocab_file_path=\"\" ## Vocab File for model.          Sample : \"/content/drive/My Drive/Experiments/uncased_L-12_H-768_A-12/vocab.txt\"\n",
        "tokenizer_path=\"\" ## Path to json file corresponding to the tokenizer Sample : \"/content/drive/My Drive/btp/bert_increased_vocab/hindi_bert/vocabs/docsampled_hin_en_fr_mar_pan_guj_de_nl_fy_es_pt_it_multibpe_0.3.json\"\n",
        "model_path=\"\" ## Model checkpoint path. Either Pytorch or Tensorflow.              \n",
        "              ## Tensorflow Sample : \"/content/drive/My Drive/btp/bert_increased_vocab/hindi_bert/jun_expts/MultiLang/bpe/docsampled_hin_en_fr_mar_pan_guj_de_nl_fy_es_pt_it_multibpe_0.5/model.ckpt-192000\"\n",
        "              ## Pytorch    Sample : \"/content/drive/My Drive/Experiments/English_RelateLM_Bengali/model.pt\"\n",
        "model_type='' ## 'tensorflow' or 'pytorch'\n",
        "dataset_path=\"\" ## Directory containing NER data. Sample: \"/content/drive/MyDrive/btp/xtreme/download/xnli/\"\n",
        "train_lang= ##Languages for training Sample: 'fr'\n",
        "test_langs= ##Languages for testing Sample: ['fr','es','pt','it']\n",
        "out_folder=\"\" ## Directory to save the checkpoints after each epoch. Sample : \"/content/drive/My Drive/btp/bert_increased_vocab/hindi_bert/jun_expts/MultiLang/bpe/docsampled_hin_en_fr_mar_pan_guj_de_nl_fy_es_pt_it_multibpe_0.5/XNLI_run1\"\n",
        "train(out_folder,dataset_path,bert_config_path,model_type,model_path,do_lower_case,train_lang,test_langs, epochs,eval_every_steps,MAX_SEQ_LEN, nn.CrossEntropyLoss(),learning_rate,batch_size,float(\"Inf\"),tokenizer_path=tokenizer_path)\n"
      ],
      "metadata": {
        "id": "lm0q8FVrhJle"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}